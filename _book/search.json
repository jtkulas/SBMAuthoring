[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Technical Communication for the Social, Behavioral, and Management Sciences",
    "section": "",
    "text": "Overview\nThis is a working outline of the curricular syllabus1 for a 15-week course on communication via literate programming principles for data science applications.\nTraditionally, within the social, behavioral, and management sciences, your analyses were performed within a secondary platform2 – completely independent from your primary authoring space (e.g., a typewriter, Word, PowerPoint). Literate programming principles obviate this orientation… the analyses and authoring have equal priority and take place within the same software space and your orientation is that of a storyteller.\nBenefits of adopting a literate programming workflow include greater:\nThe primary programming languages accommodated as of September 2025 are:\nThe focal authoring platform is Quarto, although historical (e.g., \\(\\LaTeX\\)3) and contemporary alternatives (e.g., rMarkdown) also will be addressed.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "index.html#intended-audience",
    "href": "index.html#intended-audience",
    "title": "Technical Communication for the Social, Behavioral, and Management Sciences",
    "section": "Intended audience",
    "text": "Intended audience\nGraduate students within the social, behavioral, and management sciences who would like to learn how to wrap analyses and supporting documentation within one authoring platform toward producing occupationally relevant…\n\n\n\nPresentations\nManuscripts\nReports\n\n\n\nDashboards\nWebsites\nBooks\n\n\n\nCourse content Version 0.1 is primarily informed by end-use-cases of Industrial Psychologists who gravitate toward data science applications, but the hope is that Versions X.X will reflect broader occupational applications.\nFull curricular content (Version 0.1) is located in Table 1.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "index.html#course-schedule",
    "href": "index.html#course-schedule",
    "title": "Technical Communication for the Social, Behavioral, and Management Sciences",
    "section": "Course schedule",
    "text": "Course schedule\n\n\n\n\nTable 1: Tentative schedule\n\n\n\n\n\n\nWeek\nSection\nTopic\n\n\n\n\nWeek 1\nFundamentals\nIntro\n\n\nWeek 2\n\nPlatforms\n\n\nWeek 3\n\nLanguages\n\n\nWeek 4\n\nmarkdown & \\(\\LaTeX\\)\n\n\nWeek 5\n\nhtml, css & packages\n\n\nWeek 6\nProducts\nPresentations\n\n\nWeek 7\n\nManuscripts\n\n\nWeek 8\n\nTheses & Dissertations\n\n\nWeek 9\n\nDashboards\n\n\nWeek 10\n\nTechnical Reports\n\n\nWeek 11\n\nFeedback Reports\n\n\nWeek 12\n\nWebsites\n\n\nWeek 13\n\nBooks\n\n\nWeek 14\nDistribution\nSecurity\n\n\nWeek 15\n\nSharing",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "index.html#purpose",
    "href": "index.html#purpose",
    "title": "Technical Communication for the Social, Behavioral, and Management Sciences",
    "section": "Purpose",
    "text": "Purpose\nThe purpose of this course is to introduce practitioners to a work process that integrates all components of work into one platform. This is not merely “using rMarkdown” – this is a broader philosophy of work. For example, reproducible research standards and principles are facilitated by adopting literate programming into work processes, but reproducibility (e.g., Stodden, Leisch, and Peng 2014) is only one of many derivatives of literate programming.\nThis syllabus, for example, showcases a few pedagogical enhancements:\n\nExternal resources and opportunities for feedback are accessible via links in the upper right-hand toolbar.\nAnnotation and note-taking capabilities are enabled (via hypothesis) and accessed via floating icons located in the far upper-right sidebar of the browser window.\nScreen reader functionality is enabled by default (screen-readers will pick up alternative text descriptions that are provided for each image).\n\nThese are just a few of very many latent features (quite easily) accessible when employing literate programming practices – and we haven’t even discussed anything “analytical” yet…\nThe next few pages showcase some additional capabilities currently available within literate programming platforms that may further entice a data scientist practitioner to adopt literate programming principles.\nFor additional encouragement regarding literate programming adoption, please see our customer sales rep pictured in Figure 1.\n\n\n\n\n\n\n\n\n\n\nFigure 1: C’mon… ya know you should be leverage literate programming in your work!!\n\n\n\n\n\nStodden, Victoria, Friedrich Leisch, and Roger D Peng. 2014. Implementing Reproducible Research. Crc Press Boca Raton, FL.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "Technical Communication for the Social, Behavioral, and Management Sciences",
    "section": "",
    "text": "and maybe eventually “textbook”-ish content↩︎\nExcel, GAUSS, SAS, SPSS, STATA, etc…↩︎\n\\(\\LaTeX\\) is technically a typesetting system commonly executed within an application such as Overleaf that compiles \\(\\LaTeX\\) content into formatted documents.↩︎",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Intro",
    "section": "",
    "text": "1.1 Code Access\nThe code you use to produce analytical outcomes and summaries is the lifeblood of your work as a data science practitioner.\nLiterate programming platforms provide unique tools for code access that are enabled at the document/presentation-level, if desired. For example, you may have collaborators who wish to inspect code or you may be documenting your code to provide full transparency for the process(es) used to conduct an analysis.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Intro</span>"
    ]
  },
  {
    "objectID": "intro.html#code-access",
    "href": "intro.html#code-access",
    "title": "1  Intro",
    "section": "",
    "text": "1.1.1 Code sharing\nThe code represented in Listing 1.1 (and all example pieces of code) can be copied by activating the clipboard option in the upper-right hand corner of the code chunk.\n\n\n\n\n\n\n\nTip\n\n\n\nCode can always be copied onto your personal computer via the clipboard icon: .\n\n\n\n\n\nListing 1.1: Addition within R\n\n\n1 + 1                                    \n\n\n\n\nFor more complex bits of analysis, hidden annotations are available (the reader can further access notes/assistance by hovering over the circled numbers):\n\n1library(psych)\n2data(bfi)\n\n3bfi$jibberish &lt;- rowMeans(bfi[1:10], na.rm=TRUE)\nbfi$gobbleyjook &lt;- rowMeans(bfi[11:20], na.rm=TRUE)\n\n\n1\n\nThe psych package contains example data that we can access.\n\n2\n\nThis gives us access to the bfi dataset that contains personality item responses.\n\n3\n\nWe make 2 scale scores, jibberish and gobbleyjook. The $ notation indicates that these scale scores will be appended to the bfi dataframe.\n\n\n\n\nThe entire code block can also be hidden unless asked-for. These features permit reviewers/collaborators of different need or curiosity to access source code on an as-needed basis:\n\n\nCode\n1library(psych)\n2data(bfi)\n\n3bfi$jibberish &lt;- rowMeans(bfi[1:10], na.rm=TRUE)\nbfi$gobbleyjook &lt;- rowMeans(bfi[11:20], na.rm=TRUE)\n\n\n\n1\n\nThe psych package contains example data that we can access.\n\n2\n\nThis gives us access to the bfi dataset that contains personality item responses.\n\n3\n\nWe make 2 scale scores, jibberish and gobbleyjook. The $ notation indicates that these scale scores will be appended to the bfi dataframe.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Intro</span>"
    ]
  },
  {
    "objectID": "intro.html#sec-summary",
    "href": "intro.html#sec-summary",
    "title": "1  Intro",
    "section": "1.2 Data Summaries",
    "text": "1.2 Data Summaries\nSummaries of your analyses are typically the most important (to external review) aspect of your work. These are the illustrations of your story. The primary principles of analyses within a literate programming framework are:\n\nPreserve the source data\nDocument all manipulations\n\nBelow you can find a few data presentation enhancements that are enabled via literate programming platforms.\n\n1.2.1 Data vizualizations\nFigure 1.1 demonstrates lightbox capabilities for images embedded within literate programming reports, whereby “clicking” isolates the image for closer inspection. This is useful for images that contain fine detail, user devices that may not display optimally, drawing focus to specific data features, and increasing accessibility for visually impaired viewers.\n\n\n\n\n\n\nFigure 1.1: Data visualization through a literate programming lens\n\n\n\nFigure 1.2 highlights standard interactive components for graphical representations of data. These interactive components are fully accessible within the source document/presentation.\n\n\n\n\n\n\n\n\nFigure 1.2: Example interactive plot\n\n\n\n\nFigure 1.3 is another example of interactivity - a map such as this can help reinforce viewer concepts such as representativeness within normative samples (e.g., where the data “came from” and who the data represents). The audience can get a sense of geographic representation by “zooming out” or “zooming in” and verifying that only North America is represented within this dataset.\n\n\n\n\n\n\n\n\nFigure 1.3: Example normative representation by geographic location.\n\n\n\n\n\n\n1.2.2 Informational Tutorials\nVideo 1.1 shows another example - videos can be pulled from external sites (like this tutorial on parameterized reporting within Quarto) or can present locally produced video files.\n\n\n\n\n\n\nVideo 1.1: Parameterized reports",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Intro</span>"
    ]
  },
  {
    "objectID": "platforms.html",
    "href": "platforms.html",
    "title": "2  Platforms",
    "section": "",
    "text": "2.0.1 RStudio\nYou can author within any text editor (including, for example, Windows- or Mac-based editors such as notepad or TextEdit). However, most content creators prefer to use an integrated development environment (IDE). Popular IDEs that facilitate literate programming across languages (e.g., R/Python) include:\nNote that many IDE options exist as of September 2025. Your choice of IDE is not limited to these above-listed options. If you prefer a different IDE1, please let the instructor know so he/she can:",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Platforms</span>"
    ]
  },
  {
    "objectID": "platforms.html#version-control",
    "href": "platforms.html#version-control",
    "title": "2  Platforms",
    "section": "2.1 Version Control",
    "text": "2.1 Version Control\nHere are the top 5 version control platforms particularly suited for data scientists:\n\n2.1.1 DVC (Data Version Control)\nThis open-source tool is specifically designed for managing data, models, and experiments in machine learning projects. It provides a Git-like experience for versioning data, which is crucial for reproducibility and collaboration in data science. DVC works on top of Git repositories and can use cloud storage for datasets and models, making it ideal for handling large data files.\n\n\n2.1.2 GitLab\nWhile primarily known as a DevOps platform, GitLab offers robust version control with additional features tailored for data science projects. It includes CI/CD pipelines that can be used for machine learning workflows, project management, and issue tracking, which are beneficial for coordinating complex data science projects. GitLab also allows for private repositories, which is important for sensitive data.\n\n\n2.1.3 DagsHub\nDagsHub is built for data scientists and machine learning engineers, integrating with tools like Git, DVC, MLflow, and Jenkins. It offers a platform where you can version control code, data, models, and experiments all in one place. It provides easy data access, experiment tracking, and model registry, making it a comprehensive solution for collaborative data science work.\n\n\n2.1.4 Pachyderm\nPachyderm is another platform that excels in data versioning, particularly for machine learning workflows. It offers a Git-like workflow for versioning not just code but also data, ensuring reproducibility and traceability. Pachyderm can manage petabytes of data, supports incremental processing, and has features for parallelization, which are vital for scaling data science projects.\n\n\n2.1.5 lakeFS\nAn open-source data lake versioning system, lakeFS provides Git-like semantics for managing data in data lakes. It supports various data formats and integrates with orchestration tools commonly used in data science, like Airflow and Kubeflow. It’s designed for teams needing to version control large volumes of data across different cloud storage solutions.\nThese platforms stand out by offering features that address the specific needs of data scientists, such as handling large datasets, model versioning, experiment tracking, and facilitating collaboration on data-driven projects.\nHere’s a contrast between GitHub and the top 5 version control platforms for data scientists:\nGitHub General Purpose: GitHub is primarily designed for code version control, collaboration, and open-source software development. It’s not specifically tailored for managing large datasets or machine learning experiments. Data Handling: GitHub has limitations with file size (max 2 GB per file with Git LFS for larger files), making it less suitable for versioning large datasets directly. Integration: While GitHub Actions can be used for CI/CD, including for data science projects, it lacks native integration with data versioning tools like DVC out of the box. Experiment Tracking: GitHub doesn’t have built-in tools for tracking ML experiments or managing model versions. This functionality would need to be added through third-party integrations or custom setups. Cost: Free for public repositories; private repositories and additional features like GitHub Advanced Security come at a cost for larger teams or enterprises.\n\nDVC (Data Version Control) Specialization: DVC extends Git’s capabilities specifically for data versioning. It tracks data changes but stores the actual data externally (e.g., in cloud storage). Integration: Works seamlessly with Git, allowing you to use GitHub or any Git hosting for metadata while keeping data in separate storage solutions. Experiment Management: Offers features for experiment management, which GitHub does not natively support.\n\nCost: Open-source and free, but you need to manage your data storage costs.\n\nGitLab All-in-One: GitLab integrates version control with CI/CD, project management, and issue tracking, which can be more comprehensive for data science projects than GitHub’s offerings. Data Science Features: GitLab provides some native support for ML model versioning and can interact with DVC for data versioning, but it’s not as specialized as DVC itself. Integration: Has built-in support for ML pipelines and can be more directly tailored for data science workflows out of the box compared to GitHub. Cost: Similar pricing model to GitHub, with free plans for public projects and paid plans for private ones.\nDagsHub Focused on ML: DagsHub is explicitly built for data scientists, providing a unified platform for code, data, and experiment versioning. Integration: Integrates with Git for code versioning, DVC for data versioning, and MLflow for experiment tracking, offering a more cohesive environment for ML projects compared to GitHub’s broader software focus. Usability: Offers a GitHub-like interface but with added features for data science, making it easier for data scientists to manage their work.\n\nCost: Free for public projects, with paid plans for additional features like private repositories and increased data storage.\n\nPachyderm Data Scale: Designed for versioning and processing large datasets, offering Git-like versioning for data at scale, something GitHub does not natively handle well. Workflow: Focuses on data lineage and reproducibility for ML workflows, providing a different paradigm than GitHub, which is more code-centric. Integration: Can integrate with GitHub for code but primarily works with data lakes or cloud storage for data versioning. Cost: Open-source with enterprise options for support and additional features.\nlakeFS Data Lake Focus: lakeFS is geared towards managing data in data lakes with Git-like operations, which is not a feature GitHub directly supports. Versioning: Allows versioning of raw data, which can be crucial for data science projects dealing with large datasets over time. Integration: Can link with GitHub for code management but focuses on data versioning in storage solutions like S3. Cost: Open-source, with an enterprise version for additional support and features.\n\nGitHub is excellent for code versioning but falls short in directly handling the specific needs of data scientists dealing with:\n\nlarge datasets\nmodel versioning\nexperiment tracking\n\nPlatforms like DVC, DagsHub, or Pachyderm provide more tailored solutions for these needs, integrating with or extending Git’s functionality, while GitLab offers a broad platform with capabilities that can be adapted for data science. LakeFS addresses data versioning in data lakes uniquely compared to GitHub’s code-centric approach.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Platforms</span>"
    ]
  },
  {
    "objectID": "platforms.html#footnotes",
    "href": "platforms.html#footnotes",
    "title": "2  Platforms",
    "section": "",
    "text": "for example, if you intend to only use Python as an analytical language and are already comfortable using Jupyter or Spyder↩︎",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Platforms</span>"
    ]
  },
  {
    "objectID": "languages.html",
    "href": "languages.html",
    "title": "3  Languages",
    "section": "",
    "text": "3.1 Markdown\nImmediate feedback for the effect of formatting on text in these markdown editors. You should be able to get a sense of how text is treated by exploring – the general structure of markdown is portable across platforms, so it is helpful to know, although regional dialects will exhibit slight discrepancies (for example, rMarkdown shares many elements but minor peculiarities arise – GitHub flavored markdown has its own rules as well). The original specification is most commonly attributed to Gruber (2004a) and Gruber (2004b). Summaries of these can be found on Gruber’s active website.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Languages</span>"
    ]
  },
  {
    "objectID": "languages.html#markdown",
    "href": "languages.html#markdown",
    "title": "3  Languages",
    "section": "",
    "text": "3.1.1 StackEdit\nStackEdit does not require any download and is fully operable within a browser.\n\n\n\n\n\n\nFigure 3.1: Screenshot of StackEdit interface\n\n\n\n\n\n3.1.2 HackMD\n\n\n\n\nGruber, John. 2004a. “Introducing Markdown.” https://daringfireball.net/2004/03/introducing_markdown.\n\n\n———. 2004b. “Markdown Syntax Documentation.” https://daringfireball.net/projects/markdown/syntax.\n\n\nKnuth, Donald Ervin. 1984. The \\(\\TeX\\)Book. Addison-Wesley Reading, MA.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Languages</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Allaire, J J, and Hadley Wickham. 2022. “RStudio: 2022 and\nBeyond.” https://www.youtube.com/watch?v=u1Gzxg8Pd08.\n\n\nGruber, John. 2004a. “Introducing Markdown.”\nhttps://daringfireball.net/2004/03/introducing_markdown.\n\n\n———. 2004b. “Markdown Syntax Documentation.”\nhttps://daringfireball.net/projects/markdown/syntax.\n\n\nKnuth, Donald Ervin. 1984a. The $\\TeX$Book. Addison-Wesley Reading, MA.\n\n\n———. 1984b. “Literate Programming.” The Computer\nJournal 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.\n\n\nLamport, Leslie. 1985. $\\LaTeX$ – a Document Preparation\nSystem – User’s Buide and Reference Manual. Addison-Wesley Reading,\nMA.\n\n\nRamsey, Norman. 1994. “Literate Programming Simplified.”\nIEEE Software 11 (5): 97–105.\n\n\nRossini, Aaron J. 2001. Literate Statistical Practice. DSC.\n\n\nStodden, Victoria, Friedrich Leisch, and Roger D Peng. 2014.\nImplementing Reproducible Research. Crc Press Boca Raton, FL.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "history.html",
    "href": "history.html",
    "title": "Appendix A — History",
    "section": "",
    "text": "A.1 Definitions\nKnuth (1984a) developed \\(\\TeX\\) in 1978 along with METAFONT with a primary purpose of improving the formatting of mathematical expressions in his books. \\(\\TeX\\) defined spacing and layout whereas METAFONT provided fonts to use with \\(\\TeX\\). Lamport (1985) developed \\(\\LaTeX\\), with a user’s manual appearing in 1986. Both of these are considered typesetting systems – \\(\\LaTeX\\) provides macros that make \\(\\TeX\\) a bit more user-friendly for full document preparation. Both Knuth and Lamport were associated with the Stanford Research Institute. WEB was introduced in 1981 and considered a literate programming system (facilitating the writing of both computer code and documentation). WEB consists of two tools: TANGLE and WEAVE. NoWeb is also an early literate programming tool for statisticians (Ramsey 1994), and is perhaps the origin of the term chunk (as in documentation chunk or code chunk). Noweb was inspired by WEB, but had no language specificity (WEB was intended to produce either Pascal [WEB] or C code [CWEB]). NoWeb had similar tools: notangle and noweave. Rossini (2001) coined the term “Literate Statistical Practice” – his background being statistics, whereas Knuth is a computer scientist.\nStodden, Leisch, and Peng (2014) cite Sweave as an early implementation of Knuth (1984b)’s initial principles. Yihui Xie built upon the Sweave framework for knitr.\nJ.J. Allaire and Hadley Wickham noted their corporate charter at the Posit rebrand, with an forward-focused emphasis placed on technical communication (vid-allaire?)\nLiterate Programming is a methodology for writing computer programs where the focus is on explaining to human beings what the program does rather than just instructing the computer.\nLiterate Programming Principles are substantive elements of computer science-derived philosophy that can be applied to domains beyond computer science. For data science, these principles include… (TBD)\n\\(\\TeX\\) a “language” (Knuth 1984a) for document formatting\nControl Sequence – \\(\\TeX\\) command consisting of escape character (\\(\\backslash\\)) and command (the text after the escape character) that permit the printing of something that is not otherwise represented on your keyboard\nMarkdown is a lightweight markup language with plain text formatting syntax. It’s designed to be easily readable in its raw form and convertible to HTML, PDF, and other formats.\nRMarkdown extends Markdown by allowing the integration of code (via chunks) into Markdown documents.\nrMarkdown is an R package that provides tools for navigating RMarkdown documents.\nPlatform\n1984: Knuth introduces the concept of Literate Programming in his article published in The Computer Journal (Knuth 1984b). He describes it as a paradigm where programs are written with the intent of being literature, where the explanation is as important as the code itself.\n1986: Knuth’s approach gains recognition when Jon Bentley writes about literate programming in his “Programming Pearls” column in Communications of the ACM, further popularizing the concept among programmers. Bentley’s columns included examples where Knuth applied literate programming to solve real-world problems, emphasizing its benefits in clarity and maintainability.\n1992: Knuth publishes “Literate Programming” as part of the CSLI Lecture Notes series, consolidating his earlier works and ideas on the subject. This book includes an anthology of his essays and serves as a comprehensive guide to the methodology, including practical examples from his work on TeX.\n1995-1996: Two notable books demonstrate the application of literate programming: + 1995: Retargetable C Compiler, A: Design and Implementation by David R. Hanson and Christopher Fraser uses a literate programming approach to explain the design and implementation of a compiler, although it was more of a post hoc documentation. + 1996: C Interfaces and Implementations: Techniques for Creating Reusable Software by David R. Hanson is often cited as an example of literate programming, despite criticisms about the simplicity of its code chunk names.\n2010s: There’s a resurgence of the literate programming idea with the advent of computational notebooks like Jupyter Notebooks. These tools allow for the integration of code, narrative text, and multimedia in a single document, embodying many of Knuth’s original principles but adapted for modern scientific computing and data science. This has brought literate programming closer to mainstream use, particularly in education and research settings.\n2020s: The concept continues to evolve, with tools like RMarkdown and Org-mode in Emacs providing environments where literate programming is not just possible but practical for everyday use. These tools focus on reproducibility and documentation, aligning with Knuth’s vision but tailored for contemporary needs in data analysis and software development.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>History</span>"
    ]
  },
  {
    "objectID": "history.html#definitions",
    "href": "history.html#definitions",
    "title": "Appendix A — History",
    "section": "",
    "text": "Allaire, J J, and Hadley Wickham. 2022. “RStudio: 2022 and Beyond.” https://www.youtube.com/watch?v=u1Gzxg8Pd08.\n\n\nKnuth, Donald Ervin. 1984a. The \\(\\TeX\\)Book. Addison-Wesley Reading, MA.\n\n\n———. 1984b. “Literate Programming.” The Computer Journal 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.\n\n\nLamport, Leslie. 1985. \\(\\LaTeX\\) – a Document Preparation System – User’s Buide and Reference Manual. Addison-Wesley Reading, MA.\n\n\nRamsey, Norman. 1994. “Literate Programming Simplified.” IEEE Software 11 (5): 97–105.\n\n\nRossini, Aaron J. 2001. Literate Statistical Practice. DSC.\n\n\nStodden, Victoria, Friedrich Leisch, and Roger D Peng. 2014. Implementing Reproducible Research. Crc Press Boca Raton, FL.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>History</span>"
    ]
  },
  {
    "objectID": "resistance.html",
    "href": "resistance.html",
    "title": "Appendix B — Resistance",
    "section": "",
    "text": "B.1 Excel\nThe primary vexing issue faced when applying these literate programming principles to your own work is institutional resistance. Your enemy is established work processes and tools. Excel is the evil leader of this cult who look to destroy you and all the promise that you bring for a utopian future where error is minimized.\nThere is nothing wrong with Excel itself as a tool. The problem is that it violates the #1 principle of data management: being able to “undo” what you’ve done. This is true of any platform that does not document manipulations. If Excel were to generate a reproducible script for all user actions, then it would not be considered evil.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Resistance</span>"
    ]
  },
  {
    "objectID": "resistance.html#culture",
    "href": "resistance.html#culture",
    "title": "Appendix B — Resistance",
    "section": "B.2 Culture",
    "text": "B.2 Culture\nThe role you are hired into – particularly in large organizations – has a history of purpose and application. You have, at least, supervisor(s) and coworkers who are used to systems and processes that have “worked for them” for (likely) a very long time. If they are operating within a data management system that does not keep a record of manipulations, they have suffered catastrophic data errors – they may not be aware that they have, but they have (or will – they are living on borrowed time).\nOvercoming embedded expectations of how work “has always been performed” is difficult, but are you willing to go along with the suboptimal process or are you willing to challenge the status quo and contribute not just “work”, but also a new & improved method of working?",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Resistance</span>"
    ]
  },
  {
    "objectID": "resistance.html#philosophy",
    "href": "resistance.html#philosophy",
    "title": "Appendix B — Resistance",
    "section": "B.3 Philosophy",
    "text": "B.3 Philosophy\nI can’t promise that this will be effective, but I can offer a philosophical frame that perhaps helps you in your battle against the evil forces of resistance…\n\nAre you okay with “contributing work” or do you want to improve the “methods of working”?\n\nThe easiest thing for organizations to do is to find skill and knowledge–sets that conform to pre–existing work demands and processes. More difficult is being receptive to different ideas regarding how work is accomplished. Are you a willing contributor within the existing system or are you someone who can advocate for system and process improvements?\nI can’t offer a solution for individual contributors, I can only hope to beat this drum in the hopes that a groundswell of grassroots will take hold and overcome the current state of resistance/adherence to inefficient but comfortable work processes… good luck, comrade!",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Resistance</span>"
    ]
  },
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Appendix C — Resources",
    "section": "",
    "text": "C.1 GitHub\nGeneral platform idea noodling and submitted issues are addressed by developers and community members, although the degree of responsiveness varies greatly. Targeted search engine queries will also pull up GitHub discussions – these are often insightful regarding current capabilities and future intentions.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Resources</span>"
    ]
  },
  {
    "objectID": "resources.html#artificial-intelligence-ai",
    "href": "resources.html#artificial-intelligence-ai",
    "title": "Appendix C — Resources",
    "section": "C.2 Artificial Intelligence (AI)",
    "text": "C.2 Artificial Intelligence (AI)\nPrimarily helpful for initial code generation (e.g., a starting point), but capabilities here are likely only limited by your own imagination and ethics.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Resources</span>"
    ]
  },
  {
    "objectID": "resources.html#open-office-hours",
    "href": "resources.html#open-office-hours",
    "title": "Appendix C — Resources",
    "section": "C.3 Open Office Hours",
    "text": "C.3 Open Office Hours\nJohn Kulas keeps “open office hours” every week on his YouTube channel (see, for example, Video C.1). The focal analytical platform is R, but anyone attempting to author anything using literate programming principles is invited to ask questions.\n\n\n\n\n\n\nVideo C.1: Example Open Office Hour session\n\n\n\n\n\n\n\nKnuth, Donald Ervin. 1984. The \\(\\TeX\\)Book. Addison-Wesley Reading, MA.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Resources</span>"
    ]
  },
  {
    "objectID": "quotes.html",
    "href": "quotes.html",
    "title": "Appendix D — Quotes",
    "section": "",
    "text": "Placeholder page for quotes that may eventually open chapters\n\nIf you merely want to produce a passably good document–something acceptable and basically readable but not really beautiful–a simpler system will usually suffice (Knuth 1984, 1)\nComputers are good at following instructions, but not at reading your mind (Knuth 1984, 9)\nError messages can be terrifying when you aren’t prepared for them; but they can be fun when you have the right attitude. Just remember that you really havn’t hurt the computer’s feelings, and that nobody will hold the errors against you. (Knuth 1984, 30)\n\n\n\n\n\nKnuth, Donald Ervin. 1984. The \\(\\TeX\\)Book. Addison-Wesley Reading, MA.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Quotes</span>"
    ]
  }
]